from pyspark.sql.window import Window
from pyspark.sql.functions import col, row_number

# Define window partitioned by customer and week, ordered by score descending
window_spec = Window.partitionBy("customerid", "week").orderBy(col("score").desc())

# Add a row number to identify the top scoring row per customer-week
df_ranked = df.withColumn("rank", row_number().over(window_spec))

# Filter to keep only the highest scoring row per customer-week
df_top_score = df_ranked.filter(col("rank") == 1).drop("rank")

# Show result
df_top_score.show()


# Re-import necessary packages after kernel reset
import pandas as pd
import numpy as np
import ace_tools as tools

# Simulate example data
np.random.seed(42)
df = pd.DataFrame({
    'customer_id': np.random.choice(range(1, 6), size=20),
    'current_month': np.random.choice(['2024-12', '2025-01', '2025-02'], size=20),
    'batch_date': pd.to_datetime(np.random.choice(pd.date_range('2025-01-01', '2025-03-31'), size=20)),
    'value': np.random.randint(1000, 5000, size=20)
})

# Step 1: Sort by customer_id, current_month, and batch_date descending
df_sorted = df.sort_values(by=['customer_id', 'current_month', 'batch_date'], ascending=[True, True, False])

# Step 2: Drop duplicates to keep the latest batch_date per customer and month
df_latest = df_sorted.drop_duplicates(subset=['customer_id', 'current_month'], keep='first')

# Reset index for clean output
df_latest.reset_index(drop=True, inplace=True)

tools.display_dataframe_to_user(name="Latest Record per Customer per Month", dataframe=df_latest)

# Step 1: Define metric groups
groups = {
    'HighRisk': ['HighRisk_NonHome_Currency_Trade_Value', 'HighRisk_NonHome_Currency_Trade_Volume'],
    'Restricted': ['Restricted_Currency_Trade_Value', 'Restricted_Currency_Trade_Volume']
}

# Step 2: Extract 90th/95th percentile thresholds from percentile_df
threshold_90 = percentile_df[percentile_df['percentile'] == 90].set_index('column')['value'].to_dict()
threshold_95 = percentile_df[percentile_df['percentile'] == 95].set_index('column')['value'].to_dict()

# Step 3: Evaluate thresholds using AND logic on wide-format data
results = []

for group, cols in groups.items():
    value_col, volume_col = cols[0], cols[1]
    
    # Threshold values
    v90, vol90 = threshold_90[value_col], threshold_90[volume_col]
    v95, vol95 = threshold_95[value_col], threshold_95[volume_col]

    # Apply AND logic filters
    mask_90 = (df_wide[value_col] > v90) & (df_wide[volume_col] > vol90)
    mask_95 = (df_wide[value_col] > v95) & (df_wide[volume_col] > vol95)

    total = len(df_wide)
    count_90 = mask_90.sum()
    count_95 = mask_95.sum()

    results.append({
        'Group': group,
        'Value 90th Threshold': round(v90, 2),
        'Volume 90th Threshold': round(vol90, 2),
        'Alerts > 90th (AND)': count_90,
        '% > 90th (AND)': f"{(count_90 / total) * 100:.1f}%",
        'Value 95th Threshold': round(v95, 2),
        'Volume 95th Threshold': round(vol95, 2),
        'Alerts > 95th (AND)': count_95,
        '% > 95th (AND)': f"{(count_95 / total) * 100:.1f}%"
    })

# Step 4: Create final DataFrame
and_alert_summary = pd.DataFrame(results)


# Define pairs of related columns
groups = {
    'HighRisk': ['HighRisk_NonHome_Currency_Trade_Value', 'HighRisk_NonHome_Currency_Trade_Volume'],
    'Restricted': ['Restricted_Currency_Trade_Value', 'Restricted_Currency_Trade_Volume']
}

results = []

for group_name, cols in groups.items():
    # Merge thresholds for both metrics
    thresholds = {}
    for col in cols:
        t = percentile_df[(percentile_df['column'] == col) & 
                          (percentile_df['percentile'].isin([90, 95]))]
        thresholds[col] = {
            'p90': t.loc[t['percentile'] == 90, 'value'].values[0],
            'p95': t.loc[t['percentile'] == 95, 'value'].values[0]
        }

    # Subset main data for this group
    df_sub = df[df['column'].isin(cols)].copy()

    # Pivot to wide format (each metric as a column)
    df_wide = df_sub.pivot_table(index=df_sub.index, columns='column', values='value', aggfunc='first').reset_index()

    # Apply threshold flags for both metrics
    for col in cols:
        df_wide[f'{col}_above_90'] = df_wide[col] > thresholds[col]['p90']
        df_wide[f'{col}_above_95'] = df_wide[col] > thresholds[col]['p95']

    # Union logic: flag if any metric in the group breaches threshold
    df_wide['above_90_union'] = df_wide[[f'{c}_above_90' for c in cols]].any(axis=1)
    df_wide['above_95_union'] = df_wide[[f'{c}_above_95' for c in cols]].any(axis=1)

    # Count alerts
    total = df_wide.shape[0]
    count_90 = df_wide['above_90_union'].sum()
    count_95 = df_wide['above_95_union'].sum()

    results.append({
        'Group': group_name,
        '90th Union Alerts': count_90,
        '% > 90th': f"{(count_90 / total) * 100:.1f}%",
        '95th Union Alerts': count_95,
        '% > 95th': f"{(count_95 / total) * 100:.1f}%"
    })

# Create final summary
union_summary_df = pd.DataFrame(results)



import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.stats import gaussian_kde

# Example long-format DataFrame
# df_long = pd.DataFrame({'column': [...], 'value': [...]})

columns = df_long['column'].unique()
fig = make_subplots(rows=2, cols=2, subplot_titles=columns)

# Assign each column to a subplot position
position_map = {col: (i // 2 + 1, i % 2 + 1) for i, col in enumerate(columns)}

for col in columns:
    subset = df_long[df_long['column'] == col]['value']
    kde = gaussian_kde(subset)
    x_vals = np.linspace(subset.min(), subset.max(), 200)
    y_vals = kde(x_vals)

    row, col_idx = position_map[col]
    fig.add_trace(go.Scatter(x=x_vals, y=y_vals, mode='lines', name=col), row=row, col=col_idx)

fig.update_layout(
    height=700,
    width=1000,
    title_text="KDE Density Plots by Column (Long Format)",
    showlegend=False
)

fig.show()



from kneed import KneeLocator
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Placeholder for results
results = []
df = df.copy()  # ensure we don't overwrite the original

# Loop over each unique column name in long format
for col_name in df['column'].unique():
    subset = df[df['column'] == col_name].copy()

    # Sort values in descending order
    sorted_vals = np.sort(subset['value'])[::-1]
    x = np.arange(len(sorted_vals))

    # Apply Kneedle
    kneedle = KneeLocator(x, sorted_vals, curve='convex', direction='decreasing')
    knee_val = kneedle.knee_y if kneedle.knee_y is not None else None
    knee_index = kneedle.knee

    # Store summary
    results.append({
        'column': col_name,
        'knee_index': knee_index,
        'knee_value': knee_val
    })

    # Mark above-knee rows in the original df
    if knee_val is not None:
        df.loc[(df['column'] == col_name), 'above_knee'] = df.loc[
            (df['column'] == col_name), 'value'
        ] >= knee_val
    else:
        df.loc[(df['column'] == col_name), 'above_knee'] = False

    # Optional plot
    plt.figure()
    plt.plot(x, sorted_vals, marker='o', label=col_name)
    if knee_val is not None:
        plt.axvline(knee_index, color='red', linestyle='--', label=f'Knee: {round(knee_val, 2)}')
    plt.title(f'Kneedle Detection for {col_name}')
    plt.xlabel('Index')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True)
    plt.show()

# Convert results to DataFrame
knee_results_df = pd.DataFrame(results)

# Show summary
print(knee_results_df)

results = []
for col in df['column'].unique():
    thresholds = percentile_df[(percentile_df['column'] == col) & 
                               (percentile_df['percentile'].isin([90, 95]))]
    p90 = thresholds.loc[thresholds['percentile'] == 90, 'value'].values[0]
    p95 = thresholds.loc[thresholds['percentile'] == 95, 'value'].values[0]
    
    values = df[df['column'] == col]['value']
    count_90 = (values > p90).sum()
    count_95 = (values > p95).sum()
    total = len(values)

    results.append({
        'column': col,
        '90th Percentile Value': round(p90, 2),
        'Alerts > 90th': count_90,
        '% > 90th': f"{(count_90 / total * 100):.1f}%",
        '95th Percentile Value': round(p95, 2),
        'Alerts > 95th': count_95,
        '% > 95th': f"{(count_95 / total * 100):.1f}%"
    })

summary_df = pd.DataFrame(results)

def remove_iqr_outliers(df, col_group='column', val_col='value'):
    filtered = []
    for name, group in df.groupby(col_group):
        Q1 = group[val_col].quantile(0.25)
        Q3 = group[val_col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        filtered.append(group[(group[val_col] >= lower) & (group[val_col] <= upper)])
    return pd.concat(filtered)

filtered_df = remove_iqr_outliers(percentile_df)



d# Re-import necessary libraries after environment reset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Simulate a DataFrame with multiple numeric columns
np.random.seed(42)
df = pd.DataFrame({
    'value1': np.random.normal(10, 2, 1000),
    'value2': np.random.normal(20, 5, 1000),
    'value3': np.random.normal(50, 10, 1000)
})

# Define desired percentiles
percentile_range = np.arange(0, 101, 5)

# Compute percentiles for each numeric column
percentile_records = []
for col in df.select_dtypes(include=[np.number]).columns:
    pct_values = np.percentile(df[col], percentile_range)
    for p, v in zip(percentile_range, pct_values):
        percentile_records.append({
            'column': col,
            'percentile': p,
            'value': v,
            'is_threshold': p in [90, 95]
        })

# Convert to DataFrame
percentile_df = pd.DataFrame(percentile_records)

# Visualize percentiles and thresholds
plt.figure(figsize=(12, 6))
sns.lineplot(data=percentile_df, x='percentile', y='value', hue='column', marker='o')

# Annotate threshold points
threshold_points = percentile_df[percentile_df['is_threshold']]
for _, row in threshold_points.iterrows():
    plt.text(row['percentile'], row['value'], f"{row['column']} ({row['percentile']}%)", 
             fontsize=8, ha='right', va='bottom')

plt.title("Percentile Curves with Threshold Flags (90th and 95th)")
plt.xlabel("Percentile")
plt.ylabel("Value")
plt.grid(True)
plt.legend(title="Column")
plt.tight_layout()
plt.show()

import ace_tools as tools; tools.display_dataframe_to_user(by name="Percentile Analysis with Thresholds", dataframe=percentile_df)



from pyspark.sql.functions import col

def change_data_type(df, cols, d_type):
    for c in cols:
        df = df.withColumn(c, col(c).cast(d_type))
    return df

# Cleaned list of column names
numerical_columns = [
    'HighRisk_NonHome_Currency_Trade_Value',
    'HighRisk_NonHome_Currency_Trade_Volume',
    'Restricted_Currency_Trade_Value',
    'Restricted_Currency_Trade_Volume'
]

# Apply the function to each month's DataFrame
tuning_aug = change_data_type(tuning_aug, numerical_columns, "float")
tuning_sept = change_data_type(tuning_sept, numerical_columns, "float")
tuning_oct = change_data_type(tuning_oct, numerical_columns, "float")



import matplotlib.pyplot as plt

# Get unique column names
columns = percentile_df['column'].unique()

# Set up the plot
plt.figure(figsize=(12, 6))

# Plot each column's curve
for col in columns:
    subset = percentile_df[percentile_df['column'] == col]
    plt.plot(subset['percentile'], subset['value'], marker='o', label=col)

# Highlight threshold percentiles (90th and 95th)
for col in columns:
    for p in [90, 95]:
        val = percentile_df[(percentile_df['column'] == col) & (percentile_df['percentile'] == p)]['value'].values
        if val.size > 0:
            plt.axvline(x=p, color='grey', linestyle='--', linewidth=0.5)
            plt.text(p, val[0], f"{col} {p}%", fontsize=8, va='bottom', ha='right')

# Final touches
plt.title("Percentile Curves for Multiple Columns")
plt.xlabel("Percentile")
plt.ylabel("Value")
plt.legend(title="Column")
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Copy the percentile DataFrame
plot_df = percentile_df.copy()

# Normalize values within each column
plot_df['normalized_value'] = plot_df.groupby('column')['value'].transform(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

# Plot normalized curves
plt.figure(figsize=(12, 6))
for col in plot_df['column'].unique():
    subset = plot_df[plot_df['column'] == col]
    plt.plot(subset['percentile'], subset['normalized_value'], label=col, marker='o')

plt.title("Normalized Percentile Curves")
plt.xlabel("Percentile")
plt.ylabel("Normalized Value (0 to 1)")
plt.legend(title="Column")
plt.grid(True)
plt.tight_layout()
plt.show()

# Create 2x2 subplots: Raw and Normalized for Value and Volume
fig, axes = plt.subplots(2, 2, figsize=(16, 10), sharex=True)

# Raw Trade Value (Top Left)
for col in value_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[0, 0].plot(subset['percentile'], subset['value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['value'].values
        if val.size > 0:
            axes[0, 0].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[0, 0].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Raw Trade Volume (Top Right)
for col in volume_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[0, 1].plot(subset['percentile'], subset['value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['value'].values
        if val.size > 0:
            axes[0, 1].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[0, 1].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Normalized Trade Value (Bottom Left)
for col in value_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[1, 0].plot(subset['percentile'], subset['normalized_value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['normalized_value'].values
        if val.size > 0:
            axes[1, 0].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[1, 0].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Normalized Trade Volume (Bottom Right)
for col in volume_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[1, 1].plot(subset['percentile'], subset['normalized_value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['normalized_value'].values
        if val.size > 0:
            axes[1, 1].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[1, 1].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Titles and formatting
axes[0, 0].set_title("Raw Percentiles: Trade Value")
axes[0, 1].set_title("Raw Percentiles: Trade Volume")
axes[1, 0].set_title("Normalized Percentiles: Trade Value")
axes[1, 1].set_title("Normalized Percentiles: Trade Volume")

for i in range(2):
    for j in range(2):
        axes[i, j].set_xlabel("Percentile")
        axes[i, j].grid(True)
        axes[i, j].legend()

axes[0, 0].set_ylabel("Raw Value")
axes[1, 0].set_ylabel("Normalized Value (0–1)")

plt.tight_layout()
plt.show()



import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Simulate the dataset
np.random.seed(42)
df = pd.DataFrame({
    'HighRisk_Trade_Value': np.random.normal(100000, 20000, 1000),
    'HighRisk_Trade_Volume': np.random.normal(50, 10, 1000),
    'Restricted_Trade_Value': np.random.normal(80000, 15000, 1000),
    'Restricted_Trade_Volume': np.random.normal(40, 8, 1000)
})

# Compute percentiles
percentile_range = np.arange(0, 101, 5)
records = []
for col in df.columns:
    pct_values = np.percentile(df[col], percentile_range)
    for p, v in zip(percentile_range, pct_values):
        records.append({'column': col, 'percentile': p, 'value': v})

percentile_df = pd.DataFrame(records)
percentile_df['normalized_value'] = percentile_df.groupby('column')['value'].transform(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

# Identify value vs volume columns
value_cols = [col for col in df.columns if 'Value' in col]
volume_cols = [col for col in df.columns if 'Volume' in col]

# Create subplot layout
fig = make_subplots(rows=2, cols=2, subplot_titles=[
    "Raw Percentiles: Trade Value", "Raw Percentiles: Trade Volume",
    "Normalized Percentiles: Trade Value", "Normalized Percentiles: Trade Volume"
])

# Plot raw values (top row)
for col in value_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['value'], name=col,
                             mode='lines+markers'), row=1, col=1)

for col in volume_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['value'], name=col,
                             mode='lines+markers'), row=1, col=2)

# Plot normalized values (bottom row)
for col in value_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['normalized_value'], name=col,
                             mode='lines+markers', showlegend=False), row=2, col=1)

for col in volume_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['normalized_value'], name=col,
                             mode='lines+markers', showlegend=False), row=2, col=2)

# Layout adjustments
fig.update_layout(height=800, width=1000, title_text="Interactive Percentile Analysis (Plotly)",
                  showlegend=True)

fig.update_xaxes(title_text="Percentile", row=1, col=1)
fig.update_xaxes(title_text="Percentile", row=1, col=2)
fig.update_xaxes(title_text="Percentile", row=2, col=1)
fig.update_xaxes(title_text="Percentile", row=2, col=2)

fig.update_yaxes(title_text="Raw Value", row=1, col=1)
fig.update_yaxes(title_text="Raw Value", row=1, col=2)
fig.update_yaxes(title_text="Normalized Value", row=2, col=1)
fig.update_yaxes(title_text="Normalized Value", row=2, col=2)

fig.show()



from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Define column names
column_names = [
    'HighRisk_NonHome_Currency_Trade_Value',
    'HighRisk_NonHome_Currency_Trade_Volume',
    'Restricted_Currency_Trade_Value',
    'Restricted_Currency_Trade_Volume'
]

# Create subplot layout
fig = make_subplots(rows=2, cols=2, subplot_titles=column_names)

# Format helper (e.g., 1200 -> $1.2K, 2_500_000 -> $2.5M)
def format_currency(value):
    if value >= 1_000_000:
        return f"${value/1_000_000:.1f}M"
    elif value >= 1_000:
        return f"${value/1_000:.1f}K"
    else:
        return f"${value:,.0f}"

# Get value at a specific percentile
def get_value(col, pct):
    subset = percentile_df[(percentile_df['column'] == col) & (percentile_df['percentile'] == pct)]
    return subset['value'].values[0] if not subset.empty else None

# Build chart
for idx, col_name in enumerate(column_names):
    row = 1 if idx < 2 else 2
    col = 1 if idx % 2 == 0 else 2
    data = percentile_df[percentile_df['column'] == col_name]

    # Add line chart
    fig.add_trace(go.Scatter(
        x=data['percentile'],
        y=data['value'],
        mode='lines+markers',
        name=col_name
    ), row=row, col=col)

    # Add annotations for 90th and 95th percentiles
    for pct in [90, 95]:
        y_val = get_value(col_name, pct)
        if y_val:
            fig.add_shape(
                type='line',
                x0=pct, x1=pct,
                y0=0, y1=y_val,
                line=dict(color='gray', dash='dot'),
                row=row, col=col
            )
            fig.add_annotation(
                text=f"{pct}%: {format_currency(y_val)}",
                x=pct,
                y=y_val,
                xanchor='left',
                yanchor='bottom',
                showarrow=True,
                arrowhead=2,
                font=dict(size=10),
                row=row, col=col
            )

# Layout adjustments
fig.update_layout(
    height=800,
    width=1200,
    title_text="Interactive Percentile Analysis with Currency Annotations",
    showlegend=True
)

# Axes
for r in [1, 2]:
    for c in [1, 2]:
        fig.update_xaxes(title_text="Percentile", row=r, col=c)
        fig.update_yaxes(title_text="Value", row=r, col=c)

fig.show()


from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Define columns
column_names = [
    'HighRisk_NonHome_Currency_Trade_Value',
    'HighRisk_NonHome_Currency_Trade_Volume',
    'Restricted_Currency_Trade_Value',
    'Restricted_Currency_Trade_Volume'
]

# Define which are value vs volume columns
value_cols = [c for c in column_names if 'Value' in c]
volume_cols = [c for c in column_names if 'Volume' in c]

# Create subplot layout
fig = make_subplots(rows=2, cols=2, subplot_titles=column_names)

# Format currency (for value columns)
def format_currency(value):
    if value >= 1_000_000:
        return f"${value / 1_000_000:.1f}M"
    elif value >= 1_000:
        return f"${value / 1_000:.1f}K"
    else:
        return f"${value:,.0f}"

# Format plain number (for volume columns)
def format_number(value):
    return f"{value:,.0f}"

# Get value at percentile
def get_value(col, pct):
    subset = percentile_df[(percentile_df['column'] == col) & (percentile_df['percentile'] == pct)]
    return subset['value'].values[0] if not subset.empty else None

# Build chart
for idx, col_name in enumerate(column_names):
    row = 1 if idx < 2 else 2
    col = 1 if idx % 2 == 0 else 2
    data = percentile_df[percentile_df['column'] == col_name]

    # Add the curve
    fig.add_trace(go.Scatter(
        x=data['percentile'],
        y=data['value'],
        mode='lines+markers',
        name=col_name
    ), row=row, col=col)

    # Annotate 90th and 95th percentiles
    for pct in [90, 95]:
        y_val = get_value(col_name, pct)
        if y_val:
            fig.add_shape(
                type='line',
                x0=pct, x1=pct,
                y0=0, y1=y_val,
                line=dict(color='gray', dash='dot'),
                row=row, col=col
            )
            # Apply currency only for value columns
            label = f"{pct}%: {format_currency(y_val) if col_name in value_cols else format_number(y_val)}"
            fig.add_annotation(
                text=label,
                x=pct,
                y=y_val,
                xanchor='left',
                yanchor='bottom',
                showarrow=True,
                arrowhead=2,
                font=dict(size=10),
                row=row, col=col
            )

# Layout adjustments
fig.update_layout(
    height=800,
    width=1200,
    title_text="Interactive Percentile Analysis with Value/Volume Annotations",
    showlegend=True
)

# Axes
for r in [1, 2]:
    for c in [1, 2]:
        fig.update_xaxes(title_text="Percentile", row=r, col=c)
        fig.update_yaxes(title_text="Value", row=r, col=c)

fig.show()


thresholds = {}
alert_counts = {}

for col in df.select_dtypes(include=[np.number]).columns:
    p90 = df[col].quantile(0.90)
    p95 = df[col].quantile(0.95)

    count_90 = (df[col] > p90).sum()
    count_95 = (df[col] > p95).sum()

    thresholds[col] = {'90th': p90, '95th': p95}
    alert_counts[col] = {'>90th': count_90, '>95th': count_95}


No problem — here’s the revised version for your tuning report, now incorporating both the 1st/99th percentile trimming and the Z-score method (|Z| > 2) to remove statistical outliers:

⸻

Threshold Calibration Summary

As part of the threshold tuning process, we applied a two-step outlier removal strategy to ensure a more stable and representative distribution of trade values and volumes:
	1.	Percentile-based filtering: We removed the 1st and 99th percentile values to eliminate hard-edge outliers and extreme tails.
	2.	Z-score-based filtering: We further excluded records with absolute Z-scores greater than 2 (|Z| > 2) to reduce statistical noise and extreme deviations from the mean.

Despite this dual filtering approach, the resulting data remained skewed, with sharp value increases beginning around the 85th percentile — indicating a zone of concentrated risk.

To identify suitable alert thresholds, we evaluated percentile cutoffs at the 85th, 90th, and 95th levels. Each represents a different level of sensitivity:
	•	85th percentile: Captures the top 15% of values and may be suitable for early alerting or lower-risk typologies.
	•	90th percentile: Targets the top 10% of records and offers a balanced trade-off between detection and alert volume.
	•	95th percentile: A high-severity threshold that flags only the top 5% of records, recommended for escalation scenarios.

This tiered structure supports adaptable alerting logic aligned with risk levels, operational review capacity, or typology severity.

⸻

Estimated Alert Volumes

Threshold Percentile	Approx. Volume Triggered	Recommended Use Case
85th percentile	~15% of records	Broader sensitivity / early detection
90th percentile	~10% of records	Primary alerting threshold
95th percentile	~5% of records	Escalation or critical-risk threshold


⸻

This analysis supports a recommended threshold range of 85th–95th percentile for tuning key metrics, informed by both distribution shape and post-cleaning risk concentration.

⸻

Would you like this converted into a report-ready Word or markdown document?


Absolutely — here’s the refined summary with the 85th percentile included as an additional threshold consideration:

⸻

Updated Summary with 85th Percentile:

The 90th percentile is a strong starting point for identifying potential risk, as most “normal” activity tends to fall below this level. Values above the 90th percentile may indicate anomalies or elevated risk. The 95th percentile represents a more conservative threshold, capturing only the most extreme observations. Including the 85th percentile provides an intermediate tier that helps capture early signs of escalation. Setting thresholds at the 85th, 90th, or 95th percentile allows you to flag the top 15%, 10%, or 5% of observations, respectively — each offering different levels of sensitivity for prioritizing review or escalation.

After removing the 1st and 99th percentile values to eliminate hard-edge outliers, we observed that trade values and volumes remain highly skewed, with a clear inflection point starting around the 85th percentile. Beyond this point, values increase sharply, suggesting that thresholds for alerting are best placed between the 85th and 95th percentiles — where risk concentration intensifies.

For context:
	•	An 85th percentile threshold would trigger ~15% of records
	•	A 90th percentile threshold would trigger ~10% of records
	•	A 95th percentile threshold would trigger ~5% of records

This stratified approach supports flexible alerting logic based on review capacity, risk tolerance, or escalation tiers.

⸻

Would you like me to convert this into bullet points or a slide-ready version?


from kneed import KneeLocator

sorted_vals = np.sort(df['value'])
x = np.arange(len(sorted_vals))
kneedle = KneeLocator(x, sorted_vals, curve='concave', direction='increasing')
elbow_point = sorted_vals[kneedle.knee]

plt.plot(x, sorted_vals)
plt.axvline(kneedle.knee, color='red', linestyle='--', label=f'Elbow @ {round(elbow_point, 2)}')
plt.legend()
plt.title("Kneedle Elbow Detection")
plt.show()

How to determine whether to use concave or convex and increasing or decreasing 

import pandas as pd
import numpy as np
from kneed import KneeLocator
import matplotlib.pyplot as plt

# Sample DataFrame
df = pd.DataFrame({
    'amount': [1000, 900, 850, 700, 500, 300, 200, 150, 120, 100],
    'score': [0.95, 0.92, 0.90, 0.85, 0.75, 0.60, 0.45, 0.30, 0.20, 0.10]
})

results = {}

for col in df.select_dtypes(include=np.number).columns:
    sorted_vals = np.sort(df[col])[::-1]  # descending
    x = np.arange(len(sorted_vals))

    kneedle = KneeLocator(x, sorted_vals, curve='convex', direction='decreasing')

    knee_val = kneedle.knee_y if kneedle.knee_y is not None else None

    results[col] = {
        'knee_index': kneedle.knee,
        'knee_value': knee_val
    }

    # Create a flag column indicating if the value is above the knee
    flag_col = f'{col}_above_knee'
    if knee_val is not None:
        df[flag_col] = df[col] >= knee_val
    else:
        df[flag_col] = False  # fallback if no knee detected

    # Optional plot
    plt.figure()
    plt.plot(x, sorted_vals, marker='o')
    if knee_val is not None:
        plt.axvline(kneedle.knee, color='red', linestyle='--', label=f'Knee: {round(knee_val, 2)}')
    plt.title(f'Kneedle Detection for {col}')
    plt.xlabel('Index')
    plt.ylabel(col)
    plt.legend()
    plt.grid(True)
    plt.show()

# Show final dataframe
print(df)

# Show results summary
for k, v in results.items():
    print(f"\nColumn: {k}\nKnee Index: {v['knee_index']}\nKnee Value: {v['knee_value']}")

import pandas as pd
import numpy as np
from kneed import KneeLocator
import plotly.graph_objs as go
from plotly.subplots import make_subplots

# Sample DataFrame
df = pd.DataFrame({
    'amount': [1000, 900, 850, 700, 500, 300, 200, 150, 120, 100],
    'score': [0.95, 0.92, 0.90, 0.85, 0.75, 0.60, 0.45, 0.30, 0.20, 0.10]
})

numeric_cols = df.select_dtypes(include=np.number).columns
num_cols = len(numeric_cols)

# Create subplot grid (adjust rows/cols depending on count)
cols_per_row = 2
rows = int(np.ceil(num_cols / cols_per_row))

fig = make_subplots(rows=rows, cols=cols_per_row, subplot_titles=numeric_cols)

results = {}

for idx, col in enumerate(numeric_cols):
    row = idx // cols_per_row + 1
    col_pos = idx % cols_per_row + 1

    sorted_vals = np.sort(df[col])[::-1]
    x = np.arange(len(sorted_vals))

    # Apply Kneedle
    kneedle = KneeLocator(x, sorted_vals, curve='convex', direction='decreasing')
    knee_index = kneedle.knee
    knee_val = kneedle.knee_y

    results[col] = {
        'knee_index': knee_index,
        'knee_value': knee_val
    }

    # Add flag column to DataFrame
    flag_col = f'{col}_above_knee'
    df[flag_col] = df[col] >= knee_val if knee_val is not None else False

    # Add traces to subplot
    fig.add_trace(
        go.Scatter(x=x, y=sorted_vals, mode='lines+markers', name=col, showlegend=False),
        row=row, col=col_pos
    )

    if knee_index is not None:
        fig.add_trace(
            go.Scatter(
                x=[knee_index], y=[knee_val],
                mode='markers+text',
                marker=dict(color='red', size=10),
                text=[f"{round(knee_val, 2)}"],
                textposition='top center',
                showlegend=False
            ),
            row=row, col=col_pos
        )

# Update layout
fig.update_layout(
    title='Kneedle Elbow Detection Across Numeric Columns',
    height=300 * rows,
    width=1000,
    showlegend=False
)

fig.show()

import pandas as pd
import numpy as np
import plotly.graph_objects as go

# Sample data in a DataFrame
np.random.seed(0)
df = pd.DataFrame({
    'values': np.random.normal(50, 15, 1000)
})

# Sort the values for smooth curve
df_sorted = df.sort_values(by='values').reset_index(drop=True)

# Calculate percentiles
p90 = np.percentile(df_sorted['values'], 90)
p95 = np.percentile(df_sorted['values'], 95)

# Create the curve
fig = go.Figure()

fig.add_trace(go.Scatter(
    x=df_sorted.index,
    y=df_sorted['values'],
    mode='lines',
    name='Value Curve'
))

# Add 90th and 95th percentile lines
fig.add_trace(go.Scatter(
    x=[df_sorted.index[0], df_sorted.index[-1]],
    y=[p90, p90],
    mode='lines',
    line=dict(dash='dash', color='orange'),
    name=f'90th Percentile: {p90:.2f}'
))

fig.add_trace(go.Scatter(
    x=[df_sorted.index[0], df_sorted.index[-1]],
    y=[p95, p95],
    mode='lines',
    line=dict(dash='dash', color='red'),
    name=f'95th Percentile: {p95:.2f}'
))

# Optional: add annotation text
fig.add_annotation(
    x=len(df_sorted) * 0.95, y=p90,
    text=f"90th: {p90:.2f}", showarrow=True,
    arrowhead=1, ax=0, ay=-30
)

fig.add_annotation(
    x=len(df_sorted) * 0.95, y=p95,
    text=f"95th: {p95:.2f}", showarrow=True,
    arrowhead=1, ax=0, ay=-30
)

# Final layout
fig.update_layout(
    title='Value Curve with 90th and 95th Percentile Annotations',
    xaxis_title='Index',
    yaxis_title='Value',
    showlegend=True
)

fig.show()

import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import numpy as np

# Create subplots — one row per score type
unique_scores = melted_df['Scores'].unique()
rows = len(unique_scores)
fig = make_subplots(rows=rows, cols=1, subplot_titles=unique_scores)

# Loop through each score and create KDE (density) plots
for i, score in enumerate(unique_scores, start=1):
    values = melted_df[melted_df['Scores'] == score]['Value']
    
    # Use seaborn to get density values (or use scipy if preferred)
    density = sns.kdeplot(values, bw_adjust=0.5, fill=False).get_lines()[0].get_data()
    sns.plt.clf()  # Clear the plot since we only want the data
    
    x_vals, y_vals = density
    
    fig.add_trace(
        go.Scatter(x=x_vals, y=y_vals, mode='lines', name=score),
        row=i, col=1
    )

fig.update_layout(height=300 * rows, title_text="Density Plots for Each Score", showlegend=False)
fig.show()

