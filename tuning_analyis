d# Re-import necessary libraries after environment reset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Simulate a DataFrame with multiple numeric columns
np.random.seed(42)
df = pd.DataFrame({
    'value1': np.random.normal(10, 2, 1000),
    'value2': np.random.normal(20, 5, 1000),
    'value3': np.random.normal(50, 10, 1000)
})

# Define desired percentiles
percentile_range = np.arange(0, 101, 5)

# Compute percentiles for each numeric column
percentile_records = []
for col in df.select_dtypes(include=[np.number]).columns:
    pct_values = np.percentile(df[col], percentile_range)
    for p, v in zip(percentile_range, pct_values):
        percentile_records.append({
            'column': col,
            'percentile': p,
            'value': v,
            'is_threshold': p in [90, 95]
        })

# Convert to DataFrame
percentile_df = pd.DataFrame(percentile_records)

# Visualize percentiles and thresholds
plt.figure(figsize=(12, 6))
sns.lineplot(data=percentile_df, x='percentile', y='value', hue='column', marker='o')

# Annotate threshold points
threshold_points = percentile_df[percentile_df['is_threshold']]
for _, row in threshold_points.iterrows():
    plt.text(row['percentile'], row['value'], f"{row['column']} ({row['percentile']}%)", 
             fontsize=8, ha='right', va='bottom')

plt.title("Percentile Curves with Threshold Flags (90th and 95th)")
plt.xlabel("Percentile")
plt.ylabel("Value")
plt.grid(True)
plt.legend(title="Column")
plt.tight_layout()
plt.show()

import ace_tools as tools; tools.display_dataframe_to_user(by name="Percentile Analysis with Thresholds", dataframe=percentile_df)



from pyspark.sql.functions import col

def change_data_type(df, cols, d_type):
    for c in cols:
        df = df.withColumn(c, col(c).cast(d_type))
    return df

# Cleaned list of column names
numerical_columns = [
    'HighRisk_NonHome_Currency_Trade_Value',
    'HighRisk_NonHome_Currency_Trade_Volume',
    'Restricted_Currency_Trade_Value',
    'Restricted_Currency_Trade_Volume'
]

# Apply the function to each month's DataFrame
tuning_aug = change_data_type(tuning_aug, numerical_columns, "float")
tuning_sept = change_data_type(tuning_sept, numerical_columns, "float")
tuning_oct = change_data_type(tuning_oct, numerical_columns, "float")



import matplotlib.pyplot as plt

# Get unique column names
columns = percentile_df['column'].unique()

# Set up the plot
plt.figure(figsize=(12, 6))

# Plot each column's curve
for col in columns:
    subset = percentile_df[percentile_df['column'] == col]
    plt.plot(subset['percentile'], subset['value'], marker='o', label=col)

# Highlight threshold percentiles (90th and 95th)
for col in columns:
    for p in [90, 95]:
        val = percentile_df[(percentile_df['column'] == col) & (percentile_df['percentile'] == p)]['value'].values
        if val.size > 0:
            plt.axvline(x=p, color='grey', linestyle='--', linewidth=0.5)
            plt.text(p, val[0], f"{col} {p}%", fontsize=8, va='bottom', ha='right')

# Final touches
plt.title("Percentile Curves for Multiple Columns")
plt.xlabel("Percentile")
plt.ylabel("Value")
plt.legend(title="Column")
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Copy the percentile DataFrame
plot_df = percentile_df.copy()

# Normalize values within each column
plot_df['normalized_value'] = plot_df.groupby('column')['value'].transform(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

# Plot normalized curves
plt.figure(figsize=(12, 6))
for col in plot_df['column'].unique():
    subset = plot_df[plot_df['column'] == col]
    plt.plot(subset['percentile'], subset['normalized_value'], label=col, marker='o')

plt.title("Normalized Percentile Curves")
plt.xlabel("Percentile")
plt.ylabel("Normalized Value (0 to 1)")
plt.legend(title="Column")
plt.grid(True)
plt.tight_layout()
plt.show()

# Create 2x2 subplots: Raw and Normalized for Value and Volume
fig, axes = plt.subplots(2, 2, figsize=(16, 10), sharex=True)

# Raw Trade Value (Top Left)
for col in value_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[0, 0].plot(subset['percentile'], subset['value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['value'].values
        if val.size > 0:
            axes[0, 0].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[0, 0].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Raw Trade Volume (Top Right)
for col in volume_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[0, 1].plot(subset['percentile'], subset['value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['value'].values
        if val.size > 0:
            axes[0, 1].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[0, 1].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Normalized Trade Value (Bottom Left)
for col in value_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[1, 0].plot(subset['percentile'], subset['normalized_value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['normalized_value'].values
        if val.size > 0:
            axes[1, 0].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[1, 0].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Normalized Trade Volume (Bottom Right)
for col in volume_cols:
    subset = percentile_df[percentile_df['column'] == col]
    axes[1, 1].plot(subset['percentile'], subset['normalized_value'], label=col, marker='o')
    for p in [90, 95]:
        val = subset[subset['percentile'] == p]['normalized_value'].values
        if val.size > 0:
            axes[1, 1].axvline(p, color='gray', linestyle='--', linewidth=0.5)
            axes[1, 1].text(p, val[0], f"{col} ({p}%)", fontsize=8, ha='right', va='bottom')

# Titles and formatting
axes[0, 0].set_title("Raw Percentiles: Trade Value")
axes[0, 1].set_title("Raw Percentiles: Trade Volume")
axes[1, 0].set_title("Normalized Percentiles: Trade Value")
axes[1, 1].set_title("Normalized Percentiles: Trade Volume")

for i in range(2):
    for j in range(2):
        axes[i, j].set_xlabel("Percentile")
        axes[i, j].grid(True)
        axes[i, j].legend()

axes[0, 0].set_ylabel("Raw Value")
axes[1, 0].set_ylabel("Normalized Value (0–1)")

plt.tight_layout()
plt.show()



import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Simulate the dataset
np.random.seed(42)
df = pd.DataFrame({
    'HighRisk_Trade_Value': np.random.normal(100000, 20000, 1000),
    'HighRisk_Trade_Volume': np.random.normal(50, 10, 1000),
    'Restricted_Trade_Value': np.random.normal(80000, 15000, 1000),
    'Restricted_Trade_Volume': np.random.normal(40, 8, 1000)
})

# Compute percentiles
percentile_range = np.arange(0, 101, 5)
records = []
for col in df.columns:
    pct_values = np.percentile(df[col], percentile_range)
    for p, v in zip(percentile_range, pct_values):
        records.append({'column': col, 'percentile': p, 'value': v})

percentile_df = pd.DataFrame(records)
percentile_df['normalized_value'] = percentile_df.groupby('column')['value'].transform(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

# Identify value vs volume columns
value_cols = [col for col in df.columns if 'Value' in col]
volume_cols = [col for col in df.columns if 'Volume' in col]

# Create subplot layout
fig = make_subplots(rows=2, cols=2, subplot_titles=[
    "Raw Percentiles: Trade Value", "Raw Percentiles: Trade Volume",
    "Normalized Percentiles: Trade Value", "Normalized Percentiles: Trade Volume"
])

# Plot raw values (top row)
for col in value_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['value'], name=col,
                             mode='lines+markers'), row=1, col=1)

for col in volume_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['value'], name=col,
                             mode='lines+markers'), row=1, col=2)

# Plot normalized values (bottom row)
for col in value_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['normalized_value'], name=col,
                             mode='lines+markers', showlegend=False), row=2, col=1)

for col in volume_cols:
    data = percentile_df[percentile_df['column'] == col]
    fig.add_trace(go.Scatter(x=data['percentile'], y=data['normalized_value'], name=col,
                             mode='lines+markers', showlegend=False), row=2, col=2)

# Layout adjustments
fig.update_layout(height=800, width=1000, title_text="Interactive Percentile Analysis (Plotly)",
                  showlegend=True)

fig.update_xaxes(title_text="Percentile", row=1, col=1)
fig.update_xaxes(title_text="Percentile", row=1, col=2)
fig.update_xaxes(title_text="Percentile", row=2, col=1)
fig.update_xaxes(title_text="Percentile", row=2, col=2)

fig.update_yaxes(title_text="Raw Value", row=1, col=1)
fig.update_yaxes(title_text="Raw Value", row=1, col=2)
fig.update_yaxes(title_text="Normalized Value", row=2, col=1)
fig.update_yaxes(title_text="Normalized Value", row=2, col=2)

fig.show()



from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Define column names
column_names = [
    'HighRisk_NonHome_Currency_Trade_Value',
    'HighRisk_NonHome_Currency_Trade_Volume',
    'Restricted_Currency_Trade_Value',
    'Restricted_Currency_Trade_Volume'
]

# Create subplot layout
fig = make_subplots(rows=2, cols=2, subplot_titles=column_names)

# Format helper (e.g., 1200 -> $1.2K, 2_500_000 -> $2.5M)
def format_currency(value):
    if value >= 1_000_000:
        return f"${value/1_000_000:.1f}M"
    elif value >= 1_000:
        return f"${value/1_000:.1f}K"
    else:
        return f"${value:,.0f}"

# Get value at a specific percentile
def get_value(col, pct):
    subset = percentile_df[(percentile_df['column'] == col) & (percentile_df['percentile'] == pct)]
    return subset['value'].values[0] if not subset.empty else None

# Build chart
for idx, col_name in enumerate(column_names):
    row = 1 if idx < 2 else 2
    col = 1 if idx % 2 == 0 else 2
    data = percentile_df[percentile_df['column'] == col_name]

    # Add line chart
    fig.add_trace(go.Scatter(
        x=data['percentile'],
        y=data['value'],
        mode='lines+markers',
        name=col_name
    ), row=row, col=col)

    # Add annotations for 90th and 95th percentiles
    for pct in [90, 95]:
        y_val = get_value(col_name, pct)
        if y_val:
            fig.add_shape(
                type='line',
                x0=pct, x1=pct,
                y0=0, y1=y_val,
                line=dict(color='gray', dash='dot'),
                row=row, col=col
            )
            fig.add_annotation(
                text=f"{pct}%: {format_currency(y_val)}",
                x=pct,
                y=y_val,
                xanchor='left',
                yanchor='bottom',
                showarrow=True,
                arrowhead=2,
                font=dict(size=10),
                row=row, col=col
            )

# Layout adjustments
fig.update_layout(
    height=800,
    width=1200,
    title_text="Interactive Percentile Analysis with Currency Annotations",
    showlegend=True
)

# Axes
for r in [1, 2]:
    for c in [1, 2]:
        fig.update_xaxes(title_text="Percentile", row=r, col=c)
        fig.update_yaxes(title_text="Value", row=r, col=c)

fig.show()


from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Define columns
column_names = [
    'HighRisk_NonHome_Currency_Trade_Value',
    'HighRisk_NonHome_Currency_Trade_Volume',
    'Restricted_Currency_Trade_Value',
    'Restricted_Currency_Trade_Volume'
]

# Define which are value vs volume columns
value_cols = [c for c in column_names if 'Value' in c]
volume_cols = [c for c in column_names if 'Volume' in c]

# Create subplot layout
fig = make_subplots(rows=2, cols=2, subplot_titles=column_names)

# Format currency (for value columns)
def format_currency(value):
    if value >= 1_000_000:
        return f"${value / 1_000_000:.1f}M"
    elif value >= 1_000:
        return f"${value / 1_000:.1f}K"
    else:
        return f"${value:,.0f}"

# Format plain number (for volume columns)
def format_number(value):
    return f"{value:,.0f}"

# Get value at percentile
def get_value(col, pct):
    subset = percentile_df[(percentile_df['column'] == col) & (percentile_df['percentile'] == pct)]
    return subset['value'].values[0] if not subset.empty else None

# Build chart
for idx, col_name in enumerate(column_names):
    row = 1 if idx < 2 else 2
    col = 1 if idx % 2 == 0 else 2
    data = percentile_df[percentile_df['column'] == col_name]

    # Add the curve
    fig.add_trace(go.Scatter(
        x=data['percentile'],
        y=data['value'],
        mode='lines+markers',
        name=col_name
    ), row=row, col=col)

    # Annotate 90th and 95th percentiles
    for pct in [90, 95]:
        y_val = get_value(col_name, pct)
        if y_val:
            fig.add_shape(
                type='line',
                x0=pct, x1=pct,
                y0=0, y1=y_val,
                line=dict(color='gray', dash='dot'),
                row=row, col=col
            )
            # Apply currency only for value columns
            label = f"{pct}%: {format_currency(y_val) if col_name in value_cols else format_number(y_val)}"
            fig.add_annotation(
                text=label,
                x=pct,
                y=y_val,
                xanchor='left',
                yanchor='bottom',
                showarrow=True,
                arrowhead=2,
                font=dict(size=10),
                row=row, col=col
            )

# Layout adjustments
fig.update_layout(
    height=800,
    width=1200,
    title_text="Interactive Percentile Analysis with Value/Volume Annotations",
    showlegend=True
)

# Axes
for r in [1, 2]:
    for c in [1, 2]:
        fig.update_xaxes(title_text="Percentile", row=r, col=c)
        fig.update_yaxes(title_text="Value", row=r, col=c)

fig.show()


thresholds = {}
alert_counts = {}

for col in df.select_dtypes(include=[np.number]).columns:
    p90 = df[col].quantile(0.90)
    p95 = df[col].quantile(0.95)

    count_90 = (df[col] > p90).sum()
    count_95 = (df[col] > p95).sum()

    thresholds[col] = {'90th': p90, '95th': p95}
    alert_counts[col] = {'>90th': count_90, '>95th': count_95}


No problem — here’s the revised version for your tuning report, now incorporating both the 1st/99th percentile trimming and the Z-score method (|Z| > 2) to remove statistical outliers:

⸻

Threshold Calibration Summary

As part of the threshold tuning process, we applied a two-step outlier removal strategy to ensure a more stable and representative distribution of trade values and volumes:
	1.	Percentile-based filtering: We removed the 1st and 99th percentile values to eliminate hard-edge outliers and extreme tails.
	2.	Z-score-based filtering: We further excluded records with absolute Z-scores greater than 2 (|Z| > 2) to reduce statistical noise and extreme deviations from the mean.

Despite this dual filtering approach, the resulting data remained skewed, with sharp value increases beginning around the 85th percentile — indicating a zone of concentrated risk.

To identify suitable alert thresholds, we evaluated percentile cutoffs at the 85th, 90th, and 95th levels. Each represents a different level of sensitivity:
	•	85th percentile: Captures the top 15% of values and may be suitable for early alerting or lower-risk typologies.
	•	90th percentile: Targets the top 10% of records and offers a balanced trade-off between detection and alert volume.
	•	95th percentile: A high-severity threshold that flags only the top 5% of records, recommended for escalation scenarios.

This tiered structure supports adaptable alerting logic aligned with risk levels, operational review capacity, or typology severity.

⸻

Estimated Alert Volumes

Threshold Percentile	Approx. Volume Triggered	Recommended Use Case
85th percentile	~15% of records	Broader sensitivity / early detection
90th percentile	~10% of records	Primary alerting threshold
95th percentile	~5% of records	Escalation or critical-risk threshold


⸻

This analysis supports a recommended threshold range of 85th–95th percentile for tuning key metrics, informed by both distribution shape and post-cleaning risk concentration.

⸻

Would you like this converted into a report-ready Word or markdown document?


Absolutely — here’s the refined summary with the 85th percentile included as an additional threshold consideration:

⸻

Updated Summary with 85th Percentile:

The 90th percentile is a strong starting point for identifying potential risk, as most “normal” activity tends to fall below this level. Values above the 90th percentile may indicate anomalies or elevated risk. The 95th percentile represents a more conservative threshold, capturing only the most extreme observations. Including the 85th percentile provides an intermediate tier that helps capture early signs of escalation. Setting thresholds at the 85th, 90th, or 95th percentile allows you to flag the top 15%, 10%, or 5% of observations, respectively — each offering different levels of sensitivity for prioritizing review or escalation.

After removing the 1st and 99th percentile values to eliminate hard-edge outliers, we observed that trade values and volumes remain highly skewed, with a clear inflection point starting around the 85th percentile. Beyond this point, values increase sharply, suggesting that thresholds for alerting are best placed between the 85th and 95th percentiles — where risk concentration intensifies.

For context:
	•	An 85th percentile threshold would trigger ~15% of records
	•	A 90th percentile threshold would trigger ~10% of records
	•	A 95th percentile threshold would trigger ~5% of records

This stratified approach supports flexible alerting logic based on review capacity, risk tolerance, or escalation tiers.

⸻

Would you like me to convert this into bullet points or a slide-ready version?


from kneed import KneeLocator

sorted_vals = np.sort(df['value'])
x = np.arange(len(sorted_vals))
kneedle = KneeLocator(x, sorted_vals, curve='concave', direction='increasing')
elbow_point = sorted_vals[kneedle.knee]

plt.plot(x, sorted_vals)
plt.axvline(kneedle.knee, color='red', linestyle='--', label=f'Elbow @ {round(elbow_point, 2)}')
plt.legend()
plt.title("Kneedle Elbow Detection")
plt.show()

How to determine whether to use concave or convex and increasing or decreasing 

import pandas as pd
import numpy as np
from kneed import KneeLocator
import matplotlib.pyplot as plt

# Sample DataFrame
df = pd.DataFrame({
    'amount': [1000, 900, 850, 700, 500, 300, 200, 150, 120, 100],
    'score': [0.95, 0.92, 0.90, 0.85, 0.75, 0.60, 0.45, 0.30, 0.20, 0.10]
})

results = {}

for col in df.select_dtypes(include=np.number).columns:
    sorted_vals = np.sort(df[col])[::-1]  # descending
    x = np.arange(len(sorted_vals))

    kneedle = KneeLocator(x, sorted_vals, curve='convex', direction='decreasing')

    knee_val = kneedle.knee_y if kneedle.knee_y is not None else None

    results[col] = {
        'knee_index': kneedle.knee,
        'knee_value': knee_val
    }

    # Create a flag column indicating if the value is above the knee
    flag_col = f'{col}_above_knee'
    if knee_val is not None:
        df[flag_col] = df[col] >= knee_val
    else:
        df[flag_col] = False  # fallback if no knee detected

    # Optional plot
    plt.figure()
    plt.plot(x, sorted_vals, marker='o')
    if knee_val is not None:
        plt.axvline(kneedle.knee, color='red', linestyle='--', label=f'Knee: {round(knee_val, 2)}')
    plt.title(f'Kneedle Detection for {col}')
    plt.xlabel('Index')
    plt.ylabel(col)
    plt.legend()
    plt.grid(True)
    plt.show()

# Show final dataframe
print(df)

# Show results summary
for k, v in results.items():
    print(f"\nColumn: {k}\nKnee Index: {v['knee_index']}\nKnee Value: {v['knee_value']}")

import pandas as pd
import numpy as np
from kneed import KneeLocator
import plotly.graph_objs as go
from plotly.subplots import make_subplots

# Sample DataFrame
df = pd.DataFrame({
    'amount': [1000, 900, 850, 700, 500, 300, 200, 150, 120, 100],
    'score': [0.95, 0.92, 0.90, 0.85, 0.75, 0.60, 0.45, 0.30, 0.20, 0.10]
})

numeric_cols = df.select_dtypes(include=np.number).columns
num_cols = len(numeric_cols)

# Create subplot grid (adjust rows/cols depending on count)
cols_per_row = 2
rows = int(np.ceil(num_cols / cols_per_row))

fig = make_subplots(rows=rows, cols=cols_per_row, subplot_titles=numeric_cols)

results = {}

for idx, col in enumerate(numeric_cols):
    row = idx // cols_per_row + 1
    col_pos = idx % cols_per_row + 1

    sorted_vals = np.sort(df[col])[::-1]
    x = np.arange(len(sorted_vals))

    # Apply Kneedle
    kneedle = KneeLocator(x, sorted_vals, curve='convex', direction='decreasing')
    knee_index = kneedle.knee
    knee_val = kneedle.knee_y

    results[col] = {
        'knee_index': knee_index,
        'knee_value': knee_val
    }

    # Add flag column to DataFrame
    flag_col = f'{col}_above_knee'
    df[flag_col] = df[col] >= knee_val if knee_val is not None else False

    # Add traces to subplot
    fig.add_trace(
        go.Scatter(x=x, y=sorted_vals, mode='lines+markers', name=col, showlegend=False),
        row=row, col=col_pos
    )

    if knee_index is not None:
        fig.add_trace(
            go.Scatter(
                x=[knee_index], y=[knee_val],
                mode='markers+text',
                marker=dict(color='red', size=10),
                text=[f"{round(knee_val, 2)}"],
                textposition='top center',
                showlegend=False
            ),
            row=row, col=col_pos
        )

# Update layout
fig.update_layout(
    title='Kneedle Elbow Detection Across Numeric Columns',
    height=300 * rows,
    width=1000,
    showlegend=False
)

fig.show()